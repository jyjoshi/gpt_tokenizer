# Notes

## Introduction

BPE: Byte Pair Encoding

We will build bpe from scratch

Tokenization is at the heart of much weirdness in LLMs and we can not brush it off!!!
Here's a list of problems caused due to improper/insufficient tokenization:

- Why can't llms spell words?
- Why is llm bad at simple arithmetic?
- Why is llm bad at Non-English languages?
- What is the real root of suffering?

The answer to all the questions phrased aboved is **TOKENIZATION**
